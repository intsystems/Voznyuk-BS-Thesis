\section{Обзор литературы}

Существует довольно много работ, посвященных бинарной классификации автора текста~\cite{uchendu-etal-2020-authorship, uchendu-etal-2021-turingbench-benchmark, macko-etal-2023-multitude}, поэтому для решении задачи детекции гибридных текстов одним из возможных подходов является разбиение текста на фрагменты и решение подзадачи бинарной классификации для каждого фрагмента отдельно. Самым простым способом является подразбиение на предложения. 

Пусть известно, что в документах может быть произвольное число смен авторов, но смена идет строго по предложениям. Так, в статье SeqXGPT~\cite{wang-etal-2023-seqxgpt} представлена модель, которая оценивает отдельно автора каждого предложения в документе. Одним из методов является решение задачи бинарной классификации для каждого предложения отдельно. Вторым методом, не предполагающим разбиение на предложения, является сопоставление меток ``HUMAN'' и ``MACHINE'' для каждого слова в документе. Метку же предложения предлагается определять большинством меток внутри предложения. Модель SeqXGPT основана как раз на втором способе и для сопоставления меток использует признаки, полученные из открытых моделей. Для документа $\overline{\mathbf{x}}$ и для токена $x_i \in \overline{\mathbf{x}}$ подсчитываются значения $$ll_{\theta_n}(x_i) = \log p_{\theta_n}(x_i | x_{<i}),$$ где $\theta_1, \dots, \theta_n$ - некоторые открытые языковые модели. Авторы предлагают воспринимать $\overline{ll_{\theta_n}(\overline{\mathbf{x}})}$ как понимание моделью $\theta_n$ семантики и синтаксиса текста $\overline{\mathbf{x}}$. Более продвинутые модели будут способны обрабатывать более сложные лингвистические структуры, поэтому и значение логарифма вероятности у них может быть больше. Помимо этого, полученные списки $ll_{\theta_n}(\overline{\mathbf{x}})$ довольно чувствительны к случайности сэмплирования, изменениям в обучающих данных, поэтому авторы предлагают рассматривать эти списки как волны. Вдохновившись методами обработки сигналов, а именно свёртками, авторы предлагают использовать их для получения незашумленных значений. Применив сверточные слои, получившиеся скрытые переменные передаются на слой с вниманием, после которого наконец применяется стандартный линейный слой для классификации на классы. В качестве метрики авторы подсчитывают F1-меру относительно каждого предложения в тексте. SeqXGPT совсем немного обходит по метрикам базовое решение с RoBERTa~\cite{roberta}, которая присваивает всем словам в документе метки ``HUMAN'' и ``MACHINE''~--- 95.3 у SeqXGPT и 94.6 у RoBERTa. Дополнительно авторы показывают, что методы без обучения, такие как подсчет перплексии, использование DetectGPT~\cite{mitchell2023detectgpt} или Sniffer~\cite{li2023origin}, не особенно хорошо работают на уровне предложений, в силу обычно короткой длины предложений.

Другой работой, в которой предварительно известно что смена авторов идет строго по предложениям, является работа, посвященная поиску сгенерированных фрагментов в учебных эссе~\cite{zeng2023automatic}. Авторы рассматривают тексты, в которых есть от 1 до 3 смен авторов фрагментов~--- выбираются фрагменты человеческого текста и их позиции, и с помощью инструкции для ChatGPT генерируется оставшийся текст. Метод, предложенный в статье, основан на работе triplet-BERT~\cite{TripletLoss} сетей~--- рассматриваются триплеты, состоящие из целевого предложения, из предложения с таким же авторством, что и целевое предложение, и из предложения с другим авторством. Сначала модель на основе трансформера дообучается так, чтобы косинусное расстояние между векторными представлениями предложений одного авторства было меньше чем между векторными представлениями предложений разного авторства. После получения представлений выбирается размер окна, внутри которого будут усредняться эти представления. Для каждого предложения отдельно усредняются представления внутри окна перед целевыми предложением, вместе с векторными представлением целевого предложения, и представления в окне после целевого предложения. Для подсчета метрики берется топ-K индексов относительно расстояния между двумя усреднениями.  Было показано, что дообучение модели BERT в данном случае является критичным и значительно помогает увеличить метрики, так как помогает обучить модель различать авторов, но тем не менее, даже в лучшем случае метрика F1-меры при использовании этого метода была равна 51.2. 


В работах \cite{needmoretokens} и \cite{mireshghallah-etal-2024-smaller} показано, что длина контекста имеет значение для бинарной классификации, и на коротких текстах, в том числе и на одном предложении, сложнее делать вывод о том, сгенерировано ли оно, чем делать такой же вывод, но для более длинных текстов. Поэтому в случае достаточно продвинутых моделей, например GPT-4 или LLaMA 3, которые генерируют тексты все более хорошего качества, может быть почти невозможно на уровне одного предложения определить его автора.


Другим вариантом подзадачи является постановка, в которой в документе сначала идет часть текста, написанная человеком, а затем часть текста, продолженная большой языковой моделью. Смена авторов может проходить по границе какого-то предложения, но не обязательно. 

\label{roft}
В работе \cite{Cutler2021AutomaticDO} рассматриваются тексты из 10 предложений и требуется определить индекс, соответствующий первому предложению сгенерированного фрагмента. Для решения задачи были взяты тексты из датасета RoFT, описанном в главе ~\ref{dataset}. По сути, авторы решают задачу бинарной классификации на 10 предложениях. Они рассматривают несколько подходов, а именно классификация с помощью логистической регрессии на векторных представления отдельных предложений, полученных с помощью моделей RoBERTa и SRoBERTa~\cite{sroberta}, а также простое сравнение косинусных близостей пар соседних предложений. В качестве базового решения было предложено случайно угадывать индекс предложения, брать преобладающий класс, а также было предложено базовое решение на основе подсчёта перплексии. Авторы провели два типа экспериментов ~--- модели обучались либо на всем датасете, либо только на подмножестве, соответствующем какому-то определенному домену. Авторы сравнивали различные домены и различные генерирующий модели, и на разных комбинациях лучше сработали разные из трех методов. На большинстве доменов лидером стал подход на основе классификации векторных предложений от SRoBERTa, однако даже этот наилучший метод показал в среднем точность всего лишь 42\%, что опять-таки подтверждает сложность задачи.


В работе \cite{kushnareva2024aigenerated} рассматривают несколько новых подходов. Первый подход основан на определении индекса смены с помощью некоторой BERT-модели, например с помощью RoBERTа. Передаются сразу все предложения и разделяются токеном $[$SEP$]$. Результат классификации записывается в $[$CLS$]$ токен. Данный способ значительно превосходит по метрикам метод, в котором используется такая же BERT-модель, но которая отдельно классифицирует каждое предложение. 
Второй подход основан на получении значений перплексии из открытых моделей и классификации авторов с её помощью. В случае смены домена или стилей текстов именно этот подход показывает себя лучше всего и значительно обходит методы на основе дообучения.
Наконец, авторы исследуют методы, в которых текст воспринимается как временной ряд с изменениями внутренней размерности текста~\cite{Tulchinskii2023IntrinsicDE}. Предлагается считать значение внутренней размерности текстовых эмбеддингов внутри некоторого скользящего окна. Далее полученный временной ряд классифицируется с помощью SVM. Авторы демонстрируют, что полученные распределения для человеческого и машинного текста отличаются и их возможно различаться, однако тем не менее, на данный момент этот метод уступает методам на основе дообучения и перплексии. Однако этот метод устойчив к сменам доменов и моделей, поэтому его развитие может помочь делать более общие модели.


 Данный подход хорошо подходит для случаев, когда домен на обучающих и тестовых данных одинаков или модель генерации не меняется, в ином случае результаты заметно ухудшаются. Это объясняется тем, что при дообучении модели склонны переобучаться на детекцию определенных признаков для конкретного домена или конкретной генерирующей модели.
 
Это подтверждая гипотезу, что все же детекция по предложениям довольно ограничена и в случае более сложных моделей будет проигрывать методам, которые работают с большими фрагментами текста.

 Устойчивость моделей очень важна для качественной детекции, потому что на данный момент, почти любой детектор можно обмануть, подав как очень качественно сгенерированный текст от другой модели, так и слишком некачественный текст. Поэтому предлагается в дальнейшем использовать методы на основе перплексии, но при этом предобучать их на большом наборе синтетических данных от разнообразных моделей генерации.